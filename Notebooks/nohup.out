2024-06-08 22:50:55.960240: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-08 22:50:55.983499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 22:50:56.307736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 22:50:56.525252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-08 22:50:56.528018: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
Tensorflow: 2.16.1
GPU list: []
(126, 256, 256, 3) <class 'numpy.ndarray'>
(126,) <class 'numpy.ndarray'>
Train data (100, 256, 256, 3), (100, 2), [44 56]
Test data (26, 256, 256, 3), (26, 2), [11 15]
input_layer False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d False
dense True
prediction True
0 input_layer
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d
20 dense
21 prediction
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d        │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 604ms/step - accuracy: 0.8333 - loss: 0.7391[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m2s[0m 192ms/step - accuracy: 0.7917 - loss: 0.7220[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 183ms/step - accuracy: 0.7500 - loss: 0.7445[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 179ms/step - accuracy: 0.7500 - loss: 0.7159[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 178ms/step - accuracy: 0.7333 - loss: 0.7561[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 176ms/step - accuracy: 0.7176 - loss: 0.7996[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 176ms/step - accuracy: 0.6967 - loss: 0.8492[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m1s[0m 176ms/step - accuracy: 0.6799 - loss: 0.8864[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 175ms/step - accuracy: 0.6641 - loss: 0.9217[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 175ms/step - accuracy: 0.6477 - loss: 0.9566[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 175ms/step - accuracy: 0.6301 - loss: 0.9913[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.6146 - loss: 1.0202[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.5999 - loss: 1.0494[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.5877 - loss: 1.0743[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 174ms/step - accuracy: 0.5774 - loss: 1.0945[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 175ms/step - accuracy: 0.5667 - loss: 1.1185[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 173ms/step - accuracy: 0.5580 - loss: 1.1394
Epoch 1: val_loss improved from inf to 1.11004, saving model to Models/alphabet/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 260ms/step - accuracy: 0.5504 - loss: 1.1580 - val_accuracy: 0.5000 - val_loss: 1.1100
Epoch 2/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 202ms/step - accuracy: 0.5000 - loss: 0.9593[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m2s[0m 172ms/step - accuracy: 0.5000 - loss: 0.9554[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 173ms/step - accuracy: 0.4815 - loss: 1.0669[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 173ms/step - accuracy: 0.4757 - loss: 1.1117[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 174ms/step - accuracy: 0.4739 - loss: 1.1468[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4597 - loss: 1.2042[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4451 - loss: 1.2582[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4363 - loss: 1.2984[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4331 - loss: 1.3201[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4315 - loss: 1.3379[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 174ms/step - accuracy: 0.4294 - loss: 1.3533[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.4272 - loss: 1.3685[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.4249 - loss: 1.3869[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 174ms/step - accuracy: 0.4235 - loss: 1.3987[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 175ms/step - accuracy: 0.4226 - loss: 1.4086[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 175ms/step - accuracy: 0.4229 - loss: 1.4131[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 171ms/step - accuracy: 0.4228 - loss: 1.4157
Epoch 2: val_loss improved from 1.11004 to 1.09463, saving model to Models/alphabet/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 269ms/step - accuracy: 0.4226 - loss: 1.4180 - val_accuracy: 0.5000 - val_loss: 1.0946
Models/alphabet/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d        │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.4062 - loss: 1.5014[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 924ms/step - accuracy: 0.4453 - loss: 1.3770[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 930ms/step - accuracy: 0.4427 - loss: 1.3973[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 661ms/step - accuracy: 0.4370 - loss: 1.4096[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 662ms/step - accuracy: 0.4336 - loss: 1.4169
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 753ms/step - accuracy: 0.5000 - loss: 1.0946[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 753ms/step - accuracy: 0.5000 - loss: 1.0946
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 799ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 799ms/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.4500    0.8182    0.5806        11
          PD     0.6667    0.2667    0.3810        15

    accuracy                         0.5000        26
   macro avg     0.5583    0.5424    0.4808        26
weighted avg     0.5750    0.5000    0.4654        26

0 0 0.5258208381391772
0 1 0.9193425605536332
1 0 0.581437908496732
1 1 0.8838562091503268
(127, 256, 256, 3) <class 'numpy.ndarray'>
(127,) <class 'numpy.ndarray'>
Train data (101, 256, 256, 3), (101, 2), [41 60]
Test data (26, 256, 256, 3), (26, 2), [13 13]
input_layer_1 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_1 False
dense True
prediction True
0 input_layer_1
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_1
20 dense
21 prediction
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_1      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m8s[0m 542ms/step - accuracy: 0.6667 - loss: 0.7957[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m2s[0m 188ms/step - accuracy: 0.6667 - loss: 0.7829[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 182ms/step - accuracy: 0.6111 - loss: 0.9413[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 181ms/step - accuracy: 0.5938 - loss: 0.9813[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 181ms/step - accuracy: 0.5817 - loss: 1.0059[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 181ms/step - accuracy: 0.5727 - loss: 1.0311[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 181ms/step - accuracy: 0.5691 - loss: 1.0420[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m1s[0m 181ms/step - accuracy: 0.5579 - loss: 1.0621[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 181ms/step - accuracy: 0.5473 - loss: 1.0776[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 182ms/step - accuracy: 0.5426 - loss: 1.0844[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 182ms/step - accuracy: 0.5401 - loss: 1.0888[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 182ms/step - accuracy: 0.5368 - loss: 1.0916[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 182ms/step - accuracy: 0.5329 - loss: 1.0940[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 182ms/step - accuracy: 0.5306 - loss: 1.0961[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 182ms/step - accuracy: 0.5278 - loss: 1.0988[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 182ms/step - accuracy: 0.5248 - loss: 1.1035[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 183ms/step - accuracy: 0.5236 - loss: 1.1048
Epoch 1: val_loss improved from inf to 0.85860, saving model to Models/freewriting/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 280ms/step - accuracy: 0.5226 - loss: 1.1060 - val_accuracy: 0.5000 - val_loss: 0.8586
Epoch 2/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 242ms/step - accuracy: 0.5000 - loss: 1.0376[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 233ms/step - accuracy: 0.5000 - loss: 1.1625[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 234ms/step - accuracy: 0.5185 - loss: 1.1598[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 234ms/step - accuracy: 0.5139 - loss: 1.1615[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 234ms/step - accuracy: 0.5111 - loss: 1.1544[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 234ms/step - accuracy: 0.5139 - loss: 1.1378[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 234ms/step - accuracy: 0.5187 - loss: 1.1176[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m2s[0m 234ms/step - accuracy: 0.5190 - loss: 1.1137[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 234ms/step - accuracy: 0.5230 - loss: 1.1037[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 234ms/step - accuracy: 0.5241 - loss: 1.0946[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 234ms/step - accuracy: 0.5233 - loss: 1.0909[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 234ms/step - accuracy: 0.5225 - loss: 1.0901[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 234ms/step - accuracy: 0.5198 - loss: 1.0951[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 234ms/step - accuracy: 0.5175 - loss: 1.0967[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 234ms/step - accuracy: 0.5171 - loss: 1.0960[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 234ms/step - accuracy: 0.5180 - loss: 1.0936[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 232ms/step - accuracy: 0.5172 - loss: 1.0949
Epoch 2: val_loss improved from 0.85860 to 0.85147, saving model to Models/freewriting/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 349ms/step - accuracy: 0.5165 - loss: 1.0960 - val_accuracy: 0.5000 - val_loss: 0.8515
Models/freewriting/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_1      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.5000 - loss: 1.1498[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5000 - loss: 1.1641[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.4965 - loss: 1.1591[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 888ms/step - accuracy: 0.4986 - loss: 1.1469[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 888ms/step - accuracy: 0.4999 - loss: 1.1395
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5000 - loss: 0.8515[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.5000 - loss: 0.8515
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.5000    0.7692    0.6061        13
          PD     0.5000    0.2308    0.3158        13

    accuracy                         0.5000        26
   macro avg     0.5000    0.5000    0.4609        26
weighted avg     0.5000    0.5000    0.4609        26

0 0 0.5586082276047675
0 1 0.9001499423298731
1 0 0.5586082276047675
1 1 0.9001499423298731
(130, 256, 256, 3) <class 'numpy.ndarray'>
(130,) <class 'numpy.ndarray'>
Train data (104, 256, 256, 3), (104, 2), [43 61]
Test data (26, 256, 256, 3), (26, 2), [12 14]
input_layer_2 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_2 False
dense True
prediction True
0 input_layer_2
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_2
20 dense
21 prediction
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_2      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 570ms/step - accuracy: 0.5000 - loss: 3.1883[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 236ms/step - accuracy: 0.4583 - loss: 3.3096[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 237ms/step - accuracy: 0.4537 - loss: 3.2518[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 237ms/step - accuracy: 0.4444 - loss: 3.2003[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 237ms/step - accuracy: 0.4289 - loss: 3.2122[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 237ms/step - accuracy: 0.4269 - loss: 3.1600[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 238ms/step - accuracy: 0.4271 - loss: 3.1346[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 238ms/step - accuracy: 0.4336 - loss: 3.0787[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 238ms/step - accuracy: 0.4410 - loss: 3.0319[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 238ms/step - accuracy: 0.4486 - loss: 2.9816[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 238ms/step - accuracy: 0.4532 - loss: 2.9432[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 238ms/step - accuracy: 0.4583 - loss: 2.8997[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 238ms/step - accuracy: 0.4645 - loss: 2.8551[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 238ms/step - accuracy: 0.4695 - loss: 2.8219[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 238ms/step - accuracy: 0.4753 - loss: 2.7844[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 238ms/step - accuracy: 0.4801 - loss: 2.7496[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 238ms/step - accuracy: 0.4853 - loss: 2.7120[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 229ms/step - accuracy: 0.4898 - loss: 2.6798
Epoch 1: val_loss improved from inf to 2.51798, saving model to Models/house/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 321ms/step - accuracy: 0.4939 - loss: 2.6510 - val_accuracy: 0.5000 - val_loss: 2.5180
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 236ms/step - accuracy: 0.6667 - loss: 1.7211[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 239ms/step - accuracy: 0.6667 - loss: 1.6710[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 239ms/step - accuracy: 0.6667 - loss: 1.7548[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 240ms/step - accuracy: 0.6667 - loss: 1.8123[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 241ms/step - accuracy: 0.6667 - loss: 1.8603[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 242ms/step - accuracy: 0.6574 - loss: 1.9118[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 242ms/step - accuracy: 0.6553 - loss: 1.9198[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 243ms/step - accuracy: 0.6541 - loss: 1.9174[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 243ms/step - accuracy: 0.6514 - loss: 1.9185[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 243ms/step - accuracy: 0.6463 - loss: 1.9343[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 243ms/step - accuracy: 0.6399 - loss: 1.9577[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 243ms/step - accuracy: 0.6352 - loss: 1.9676[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 243ms/step - accuracy: 0.6287 - loss: 1.9840[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 243ms/step - accuracy: 0.6238 - loss: 1.9963[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 243ms/step - accuracy: 0.6192 - loss: 2.0100[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 243ms/step - accuracy: 0.6157 - loss: 2.0175[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 243ms/step - accuracy: 0.6129 - loss: 2.0207[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 234ms/step - accuracy: 0.6104 - loss: 2.0252
Epoch 2: val_loss improved from 2.51798 to 2.48594, saving model to Models/house/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 341ms/step - accuracy: 0.6081 - loss: 2.0293 - val_accuracy: 0.5000 - val_loss: 2.4859
Models/house/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_2      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.5000 - loss: 2.2599[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5234 - loss: 2.1912[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5365 - loss: 2.1309[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 958ms/step - accuracy: 0.5442 - loss: 2.1199[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 959ms/step - accuracy: 0.5488 - loss: 2.1134
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5000 - loss: 2.4859[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.5000 - loss: 2.4859
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.0000    0.0000    0.0000        12
          PD     0.5200    0.9286    0.6667        14

    accuracy                         0.5000        26
   macro avg     0.2600    0.4643    0.3333        26
weighted avg     0.2800    0.5000    0.3590        26

0 0 0.9882352941176471
0 1 0.40980392156862744
1 0 0.9611072664359861
1 1 0.45520184544405995
(102, 256, 256, 3) <class 'numpy.ndarray'>
(102,) <class 'numpy.ndarray'>
Train data (81, 256, 256, 3), (81, 2), [34 47]
Test data (21, 256, 256, 3), (21, 2), [ 8 13]
input_layer_3 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_3 False
dense True
prediction True
0 input_layer_3
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_3
20 dense
21 prediction
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_3      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/14[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 601ms/step - accuracy: 0.5000 - loss: 1.8900[1m 2/14[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 256ms/step - accuracy: 0.5833 - loss: 1.5491[1m 3/14[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 256ms/step - accuracy: 0.5741 - loss: 1.5204[1m 4/14[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 256ms/step - accuracy: 0.5660 - loss: 1.5136[1m 5/14[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 257ms/step - accuracy: 0.5661 - loss: 1.5167[1m 6/14[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 258ms/step - accuracy: 0.5644 - loss: 1.5113[1m 7/14[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 258ms/step - accuracy: 0.5620 - loss: 1.5041[1m 8/14[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 260ms/step - accuracy: 0.5620 - loss: 1.4905[1m 9/14[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 260ms/step - accuracy: 0.5654 - loss: 1.4716[1m10/14[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 260ms/step - accuracy: 0.5655 - loss: 1.4596[1m11/14[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.5637 - loss: 1.4511[1m12/14[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 260ms/step - accuracy: 0.5619 - loss: 1.4434[1m13/14[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 260ms/step - accuracy: 0.5591 - loss: 1.4433[1m14/14[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.5571 - loss: 1.4405
Epoch 1: val_loss improved from inf to 1.45720, saving model to Models/line1/Prueba_VGG16/Prueba_VGG16_model.keras
[1m14/14[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 365ms/step - accuracy: 0.5553 - loss: 1.4382 - val_accuracy: 0.4762 - val_loss: 1.4572
Epoch 2/2
[1m 1/14[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 251ms/step - accuracy: 0.5000 - loss: 1.6793[1m 2/14[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 265ms/step - accuracy: 0.4583 - loss: 2.0064[1m 3/14[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 260ms/step - accuracy: 0.4537 - loss: 1.9530[1m 4/14[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 259ms/step - accuracy: 0.4444 - loss: 1.9700[1m 5/14[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 259ms/step - accuracy: 0.4422 - loss: 1.9522[1m 6/14[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 259ms/step - accuracy: 0.4426 - loss: 1.9366[1m 7/14[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 259ms/step - accuracy: 0.4474 - loss: 1.9047[1m 8/14[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 259ms/step - accuracy: 0.4488 - loss: 1.8859[1m 9/14[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 260ms/step - accuracy: 0.4545 - loss: 1.8531[1m10/14[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 260ms/step - accuracy: 0.4590 - loss: 1.8302[1m11/14[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 260ms/step - accuracy: 0.4641 - loss: 1.8025[1m12/14[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 260ms/step - accuracy: 0.4683 - loss: 1.7773[1m13/14[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 260ms/step - accuracy: 0.4727 - loss: 1.7502[1m14/14[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.4768 - loss: 1.7248
Epoch 2: val_loss improved from 1.45720 to 1.44952, saving model to Models/line1/Prueba_VGG16/Prueba_VGG16_model.keras
[1m14/14[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 378ms/step - accuracy: 0.4804 - loss: 1.7028 - val_accuracy: 0.4762 - val_loss: 1.4495
Models/line1/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_3      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/3[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5625 - loss: 1.1445[1m2/3[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5547 - loss: 1.2485[1m3/3[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5467 - loss: 1.2947[1m3/3[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1s/step - accuracy: 0.5428 - loss: 1.3177
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 905ms/step - accuracy: 0.4762 - loss: 1.4495[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 906ms/step - accuracy: 0.4762 - loss: 1.4495
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 940ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 940ms/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(21,) (21,)
              precision    recall  f1-score   support

          HC     0.0000    0.0000    0.0000         8
          PD     0.5556    0.7692    0.6452        13

    accuracy                         0.4762        21
   macro avg     0.2778    0.3846    0.3226        21
weighted avg     0.3439    0.4762    0.3994        21

0 0 0.9882352941176471
0 1 0.40980392156862744
1 0 0.9001499423298731
1 1 0.5586082276047675
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_4 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_4 False
dense True
prediction True
0 input_layer_4
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_4
20 dense
21 prediction
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_4      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 606ms/step - accuracy: 0.8333 - loss: 0.8410[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 258ms/step - accuracy: 0.7917 - loss: 0.9775 [1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.7315 - loss: 1.1684[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.7049 - loss: 1.2114[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.6839 - loss: 1.2647[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.6671 - loss: 1.3209[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6569 - loss: 1.3720[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6451 - loss: 1.4191[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6413 - loss: 1.4347[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6388 - loss: 1.4381[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6372 - loss: 1.4393[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6339 - loss: 1.4493[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6285 - loss: 1.4720[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6244 - loss: 1.4884[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.6199 - loss: 1.5053[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 261ms/step - accuracy: 0.6163 - loss: 1.5191[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 261ms/step - accuracy: 0.6129 - loss: 1.5329[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.6101 - loss: 1.5443
Epoch 1: val_loss improved from inf to 1.70136, saving model to Models/name/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m7s[0m 352ms/step - accuracy: 0.6077 - loss: 1.5545 - val_accuracy: 0.6154 - val_loss: 1.7014
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 251ms/step - accuracy: 0.5000 - loss: 2.0584[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 260ms/step - accuracy: 0.5000 - loss: 2.1252[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 263ms/step - accuracy: 0.4815 - loss: 2.1748[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 263ms/step - accuracy: 0.4653 - loss: 2.2148[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 266ms/step - accuracy: 0.4656 - loss: 2.2074[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m3s[0m 265ms/step - accuracy: 0.4667 - loss: 2.2047[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 264ms/step - accuracy: 0.4748 - loss: 2.1820[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 264ms/step - accuracy: 0.4806 - loss: 2.1719[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 264ms/step - accuracy: 0.4869 - loss: 2.1580[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m2s[0m 264ms/step - accuracy: 0.4898 - loss: 2.1572[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 264ms/step - accuracy: 0.4921 - loss: 2.1539[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 264ms/step - accuracy: 0.4963 - loss: 2.1408[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 263ms/step - accuracy: 0.5005 - loss: 2.1209[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 263ms/step - accuracy: 0.5039 - loss: 2.1005[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 263ms/step - accuracy: 0.5073 - loss: 2.0789[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 263ms/step - accuracy: 0.5108 - loss: 2.0578[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 263ms/step - accuracy: 0.5142 - loss: 2.0370[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 252ms/step - accuracy: 0.5169 - loss: 2.0193
Epoch 2: val_loss improved from 1.70136 to 1.68116, saving model to Models/name/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 361ms/step - accuracy: 0.5193 - loss: 2.0034 - val_accuracy: 0.6154 - val_loss: 1.6812
Models/name/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_4      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.5000 - loss: 2.0424[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5312 - loss: 1.9306[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5382 - loss: 1.8700[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5444 - loss: 1.8289[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 1s/step - accuracy: 0.5482 - loss: 1.8042
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.6154 - loss: 1.6812[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.6154 - loss: 1.6812
WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb70a7ceb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.0000    0.0000    0.0000        10
          PD     0.6154    1.0000    0.7619        16

    accuracy                         0.6154        26
   macro avg     0.3077    0.5000    0.3810        26
weighted avg     0.3787    0.6154    0.4689        26

0 0 0.9882352941176471
0 1 0.40980392156862744
1 0 0.9882352941176471
1 1 0.40980392156862744
(123, 256, 256, 3) <class 'numpy.ndarray'>
(123,) <class 'numpy.ndarray'>
Train data (98, 256, 256, 3), (98, 2), [43 55]
Test data (25, 256, 256, 3), (25, 2), [11 14]
input_layer_5 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_5 False
dense True
prediction True
0 input_layer_5
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_5
20 dense
21 prediction
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_5      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 601ms/step - accuracy: 0.6667 - loss: 2.0556[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.6250 - loss: 2.2895[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5648 - loss: 2.7226[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5382 - loss: 2.8755[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5239 - loss: 2.9265[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.5060 - loss: 2.9678[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.4950 - loss: 2.9981[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.4930 - loss: 2.9765[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.4896 - loss: 2.9659[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4857 - loss: 2.9496[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4829 - loss: 2.9332[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4831 - loss: 2.9088[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4824 - loss: 2.8916[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.4795 - loss: 2.8863[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 261ms/step - accuracy: 0.4771 - loss: 2.8839[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 261ms/step - accuracy: 0.4753 - loss: 2.8769[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 250ms/step - accuracy: 0.4731 - loss: 2.8740
Epoch 1: val_loss improved from inf to 2.45512, saving model to Models/rey/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 363ms/step - accuracy: 0.4712 - loss: 2.8714 - val_accuracy: 0.4400 - val_loss: 2.4551
Epoch 2/2
[1m 1/17[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 256ms/step - accuracy: 0.6667 - loss: 2.5433[1m 2/17[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5417 - loss: 3.1456[1m 3/17[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.5278 - loss: 3.0543[1m 4/17[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5208 - loss: 2.9505[1m 5/17[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.5167 - loss: 2.8795[1m 6/17[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.5093 - loss: 2.8738[1m 7/17[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.5011 - loss: 2.8839[1m 8/17[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.4906 - loss: 2.9017[1m 9/17[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.4772 - loss: 2.9474[1m10/17[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4678 - loss: 2.9897[1m11/17[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4611 - loss: 3.0071[1m12/17[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4539 - loss: 3.0225[1m13/17[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.4476 - loss: 3.0273[1m14/17[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.4429 - loss: 3.0299[1m15/17[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 261ms/step - accuracy: 0.4400 - loss: 3.0234[1m16/17[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 261ms/step - accuracy: 0.4392 - loss: 3.0120[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.4392 - loss: 2.9986
Epoch 2: val_loss improved from 2.45512 to 2.41016, saving model to Models/rey/Prueba_VGG16/Prueba_VGG16_model.keras
[1m17/17[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 381ms/step - accuracy: 0.4391 - loss: 2.9867 - val_accuracy: 0.4400 - val_loss: 2.4102
Models/rey/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_5      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.4688 - loss: 2.7804[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.4609 - loss: 2.7010[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.4531 - loss: 2.7209[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 933ms/step - accuracy: 0.4495 - loss: 2.7301[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 934ms/step - accuracy: 0.4474 - loss: 2.7357
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.4400 - loss: 2.4102[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.4400 - loss: 2.4102
WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb708e3ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(25,) (25,)
              precision    recall  f1-score   support

          HC     0.4400    1.0000    0.6111        11
          PD     0.0000    0.0000    0.0000        14

    accuracy                         0.4400        25
   macro avg     0.2200    0.5000    0.3056        25
weighted avg     0.1936    0.4400    0.2689        25

0 0 0.40980392156862744
0 1 0.9882352941176471
1 0 0.40980392156862744
1 1 0.9882352941176471
(130, 256, 256, 3) <class 'numpy.ndarray'>
(130,) <class 'numpy.ndarray'>
Train data (104, 256, 256, 3), (104, 2), [40 64]
Test data (26, 256, 256, 3), (26, 2), [15 11]
input_layer_6 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d_6 False
dense True
prediction True
0 input_layer_6
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_6
20 dense
21 prediction
Model: "functional_13"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_6 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_6      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 602ms/step - accuracy: 0.5000 - loss: 3.5676[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 259ms/step - accuracy: 0.5833 - loss: 3.0531 [1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.6296 - loss: 2.7255[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 259ms/step - accuracy: 0.6389 - loss: 2.5309[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 260ms/step - accuracy: 0.6311 - loss: 2.4597[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m3s[0m 261ms/step - accuracy: 0.6324 - loss: 2.3842[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6271 - loss: 2.3705[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6242 - loss: 2.3532[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6187 - loss: 2.3466[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m2s[0m 261ms/step - accuracy: 0.6168 - loss: 2.3209[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6131 - loss: 2.3149[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6094 - loss: 2.3102[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6069 - loss: 2.2985[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.6044 - loss: 2.2916[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.6026 - loss: 2.2829[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 261ms/step - accuracy: 0.6021 - loss: 2.2708[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 261ms/step - accuracy: 0.6012 - loss: 2.2662[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.5999 - loss: 2.2636
Epoch 1: val_loss improved from inf to 3.87748, saving model to Models/spiral/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m7s[0m 351ms/step - accuracy: 0.5987 - loss: 2.2614 - val_accuracy: 0.3462 - val_loss: 3.8775
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 252ms/step - accuracy: 0.8333 - loss: 0.9616[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 261ms/step - accuracy: 0.7083 - loss: 1.3677[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 264ms/step - accuracy: 0.6389 - loss: 1.7183[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 265ms/step - accuracy: 0.5938 - loss: 1.9744[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 264ms/step - accuracy: 0.5750 - loss: 2.1181[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m3s[0m 264ms/step - accuracy: 0.5625 - loss: 2.1985[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 263ms/step - accuracy: 0.5570 - loss: 2.2435[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 263ms/step - accuracy: 0.5551 - loss: 2.2749[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 262ms/step - accuracy: 0.5510 - loss: 2.3174[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m2s[0m 262ms/step - accuracy: 0.5509 - loss: 2.3322[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.5490 - loss: 2.3451[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.5484 - loss: 2.3552[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.5486 - loss: 2.3575[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 261ms/step - accuracy: 0.5503 - loss: 2.3515[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 261ms/step - accuracy: 0.5521 - loss: 2.3429[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 261ms/step - accuracy: 0.5540 - loss: 2.3354[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 261ms/step - accuracy: 0.5561 - loss: 2.3260[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 251ms/step - accuracy: 0.5572 - loss: 2.3195
Epoch 2: val_loss improved from 3.87748 to 3.85748, saving model to Models/spiral/Prueba_VGG16/Prueba_VGG16_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m7s[0m 369ms/step - accuracy: 0.5583 - loss: 2.3136 - val_accuracy: 0.3462 - val_loss: 3.8575
Models/spiral/Prueba_VGG16/Prueba_VGG16_model.keras
Model: "functional_13"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_6 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_6      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.7188 - loss: 1.6693[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.6641 - loss: 1.8847[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.6372 - loss: 1.9981[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.6221 - loss: 2.0485[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1s/step - accuracy: 0.6131 - loss: 2.0788
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.3462 - loss: 3.8575[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.3462 - loss: 3.8575
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
/home/gita24/Documentos/UdeA/UdeA_Master/2_Semester/Final_Project/deep_learning/Notebooks/3_Task_Exploration_VGG16.py:47: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize = (size,size))
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.2500    0.0667    0.1053        15
          PD     0.3636    0.7273    0.4848        11

    accuracy                         0.3462        26
   macro avg     0.3068    0.3970    0.2951        26
weighted avg     0.2981    0.3462    0.2659        26

0 0 0.9626143790849673
0 1 0.4526797385620915
1 0 0.8816724336793541
1 1 0.5839907727797001
2024-06-08 22:54:04.855271: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-08 22:54:04.877918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 22:54:05.203091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 22:54:05.421543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-08 22:54:05.424216: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
Tensorflow: 2.16.1
GPU list: []
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 False
block5_conv2 False
block5_conv3 False
block5_pool False
global_average_pooling2d False
dense True
prediction True
0 input_layer
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d
20 dense
21 prediction
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d        │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
Model Training:  Prueba_VGG16_dense 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 582ms/step - accuracy: 0.6667 - loss: 1.3939[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 194ms/step - accuracy: 0.6250 - loss: 1.8371[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 184ms/step - accuracy: 0.6389 - loss: 1.8296[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 181ms/step - accuracy: 0.6250 - loss: 1.9917[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 179ms/step - accuracy: 0.6133 - loss: 2.1380[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 178ms/step - accuracy: 0.5991 - loss: 2.2918[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5883 - loss: 2.4222[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5825 - loss: 2.5016[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5774 - loss: 2.5800[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5764 - loss: 2.6209[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5749 - loss: 2.6570[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 176ms/step - accuracy: 0.5756 - loss: 2.6795[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 176ms/step - accuracy: 0.5747 - loss: 2.7109[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 176ms/step - accuracy: 0.5728 - loss: 2.7368[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 177ms/step - accuracy: 0.5717 - loss: 2.7585[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 177ms/step - accuracy: 0.5711 - loss: 2.7716[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 177ms/step - accuracy: 0.5704 - loss: 2.7912[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 172ms/step - accuracy: 0.5700 - loss: 2.8070
Epoch 1: val_loss improved from inf to 2.22172, saving model to Models/name/Prueba_VGG16_dense/Prueba_VGG16_dense_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 254ms/step - accuracy: 0.5696 - loss: 2.8212 - val_accuracy: 0.6154 - val_loss: 2.2217
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 200ms/step - accuracy: 0.6667 - loss: 1.1016[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m2s[0m 174ms/step - accuracy: 0.5833 - loss: 1.8768[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 176ms/step - accuracy: 0.5926 - loss: 1.9721[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m2s[0m 176ms/step - accuracy: 0.5903 - loss: 2.1884[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 177ms/step - accuracy: 0.5922 - loss: 2.3087[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 176ms/step - accuracy: 0.5954 - loss: 2.3668[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5988 - loss: 2.3953[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 177ms/step - accuracy: 0.5994 - loss: 2.4371[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 178ms/step - accuracy: 0.5987 - loss: 2.4756[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 178ms/step - accuracy: 0.5988 - loss: 2.4921[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 179ms/step - accuracy: 0.5981 - loss: 2.5065[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 179ms/step - accuracy: 0.5969 - loss: 2.5322[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 179ms/step - accuracy: 0.5943 - loss: 2.5695[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 179ms/step - accuracy: 0.5918 - loss: 2.6050[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 179ms/step - accuracy: 0.5894 - loss: 2.6372[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 179ms/step - accuracy: 0.5877 - loss: 2.6641[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 179ms/step - accuracy: 0.5860 - loss: 2.6883[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 172ms/step - accuracy: 0.5848 - loss: 2.7081
Epoch 2: val_loss improved from 2.22172 to 2.19434, saving model to Models/name/Prueba_VGG16_dense/Prueba_VGG16_dense_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m5s[0m 278ms/step - accuracy: 0.5836 - loss: 2.7259 - val_accuracy: 0.6154 - val_loss: 2.1943
Models/name/Prueba_VGG16_dense/Prueba_VGG16_dense_model.keras
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d        │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,912,456 (56.89 MB)
 Trainable params: 65,922 (257.51 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
 Optimizer params: 131,846 (515.03 KB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.5000 - loss: 3.4254[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m1s[0m 953ms/step - accuracy: 0.5312 - loss: 3.2012[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 946ms/step - accuracy: 0.5382 - loss: 3.1651[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 703ms/step - accuracy: 0.5444 - loss: 3.1311[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 704ms/step - accuracy: 0.5482 - loss: 3.1107
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 788ms/step - accuracy: 0.6154 - loss: 2.1943[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 789ms/step - accuracy: 0.6154 - loss: 2.1943
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 857ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 857ms/step
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.0000    0.0000    0.0000        10
          PD     0.6154    1.0000    0.7619        16

    accuracy                         0.6154        26
   macro avg     0.3077    0.5000    0.3810        26
weighted avg     0.3787    0.6154    0.4689        26

0 0 0.9882352941176471
0 1 0.40980392156862744
1 0 0.9882352941176471
1 1 0.40980392156862744
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_1 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 False
block4_conv2 False
block4_conv3 False
block4_pool False
block5_conv1 True
block5_conv2 True
block5_conv3 True
block5_pool True
global_average_pooling2d_1 True
dense True
prediction True
0 input_layer_1
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_1
20 dense
21 prediction
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_1      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 7,145,346 (27.26 MB)
 Non-trainable params: 7,635,264 (29.13 MB)
Model Training:  Prueba_VGG16_block5 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m13s[0m 787ms/step - accuracy: 0.5000 - loss: 1.6795[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 215ms/step - accuracy: 0.4583 - loss: 3.1066 [1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 218ms/step - accuracy: 0.4167 - loss: 3.5846[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 222ms/step - accuracy: 0.4167 - loss: 3.6243[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 222ms/step - accuracy: 0.4133 - loss: 3.5978[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 222ms/step - accuracy: 0.4185 - loss: 3.5236[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 222ms/step - accuracy: 0.4132 - loss: 3.5008[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 222ms/step - accuracy: 0.4136 - loss: 3.4526[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 222ms/step - accuracy: 0.4170 - loss: 3.3920[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 223ms/step - accuracy: 0.4203 - loss: 3.3404[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 223ms/step - accuracy: 0.4221 - loss: 3.3155[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 223ms/step - accuracy: 0.4216 - loss: 3.3087[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 223ms/step - accuracy: 0.4207 - loss: 3.2951[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 223ms/step - accuracy: 0.4221 - loss: 3.2696[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 223ms/step - accuracy: 0.4236 - loss: 3.2458[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 223ms/step - accuracy: 0.4264 - loss: 3.2149[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 224ms/step - accuracy: 0.4279 - loss: 3.1924[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 215ms/step - accuracy: 0.4289 - loss: 3.1740
Epoch 1: val_loss improved from inf to 1.69843, saving model to Models/name/Prueba_VGG16_block5/Prueba_VGG16_block5_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 300ms/step - accuracy: 0.4299 - loss: 3.1576 - val_accuracy: 0.3462 - val_loss: 1.6984
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 232ms/step - accuracy: 0.6667 - loss: 2.1124[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 225ms/step - accuracy: 0.5833 - loss: 2.4424[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m3s[0m 225ms/step - accuracy: 0.5185 - loss: 2.3417[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m3s[0m 227ms/step - accuracy: 0.4826 - loss: 2.2806[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 227ms/step - accuracy: 0.4528 - loss: 2.3433[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m2s[0m 227ms/step - accuracy: 0.4468 - loss: 2.3249[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m2s[0m 227ms/step - accuracy: 0.4340 - loss: 2.3267[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m2s[0m 227ms/step - accuracy: 0.4266 - loss: 2.3132[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 227ms/step - accuracy: 0.4203 - loss: 2.2997[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m1s[0m 227ms/step - accuracy: 0.4166 - loss: 2.2845[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m1s[0m 228ms/step - accuracy: 0.4118 - loss: 2.2930[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m1s[0m 228ms/step - accuracy: 0.4076 - loss: 2.2963[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m1s[0m 228ms/step - accuracy: 0.4058 - loss: 2.2895[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 229ms/step - accuracy: 0.4066 - loss: 2.2747[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 229ms/step - accuracy: 0.4076 - loss: 2.2603[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 229ms/step - accuracy: 0.4076 - loss: 2.2459[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 229ms/step - accuracy: 0.4078 - loss: 2.2293[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 220ms/step - accuracy: 0.4083 - loss: 2.2137
Epoch 2: val_loss improved from 1.69843 to 1.18388, saving model to Models/name/Prueba_VGG16_block5/Prueba_VGG16_block5_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m6s[0m 337ms/step - accuracy: 0.4088 - loss: 2.1997 - val_accuracy: 0.4231 - val_loss: 1.1839
Models/name/Prueba_VGG16_block5/Prueba_VGG16_block5_model.keras
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_1      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 29,071,304 (110.90 MB)
 Trainable params: 7,145,346 (27.26 MB)
 Non-trainable params: 7,635,264 (29.13 MB)
 Optimizer params: 14,290,694 (54.51 MB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.5000 - loss: 0.8491[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.4766 - loss: 1.1232[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.4670 - loss: 1.2632[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 810ms/step - accuracy: 0.4643 - loss: 1.3518[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 810ms/step - accuracy: 0.4627 - loss: 1.4050
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 928ms/step - accuracy: 0.4231 - loss: 1.1839[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 929ms/step - accuracy: 0.4231 - loss: 1.1839
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.3529    0.6000    0.4444        10
          PD     0.5556    0.3125    0.4000        16

    accuracy                         0.4231        26
   macro avg     0.4542    0.4562    0.4222        26
weighted avg     0.4776    0.4231    0.4171        26

0 0 0.6686274509803922
0 1 0.8058823529411764
1 0 0.609519415609381
1 1 0.8576509034986544
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_2 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 False
block3_conv2 False
block3_conv3 False
block3_pool False
block4_conv1 True
block4_conv2 True
block4_conv3 True
block4_pool True
block5_conv1 True
block5_conv2 True
block5_conv3 True
block5_pool True
global_average_pooling2d_2 True
dense True
prediction True
0 input_layer_2
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_2
20 dense
21 prediction
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_2      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 13,045,122 (49.76 MB)
 Non-trainable params: 1,735,488 (6.62 MB)
Model Training:  Prueba_VGG16_block4 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m20s[0m 1s/step - accuracy: 0.3333 - loss: 4.9233[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m5s[0m 349ms/step - accuracy: 0.3333 - loss: 4.9039[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m5s[0m 377ms/step - accuracy: 0.3519 - loss: 4.8509[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m5s[0m 386ms/step - accuracy: 0.3681 - loss: 4.7503[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m5s[0m 391ms/step - accuracy: 0.3878 - loss: 4.5988[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m4s[0m 393ms/step - accuracy: 0.3972 - loss: 4.5534[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m4s[0m 395ms/step - accuracy: 0.4051 - loss: 4.5047[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m3s[0m 397ms/step - accuracy: 0.4092 - loss: 4.4664[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m3s[0m 399ms/step - accuracy: 0.4151 - loss: 4.4086[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m3s[0m 399ms/step - accuracy: 0.4203 - loss: 4.3469[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m2s[0m 400ms/step - accuracy: 0.4220 - loss: 4.3073[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m2s[0m 401ms/step - accuracy: 0.4216 - loss: 4.2811[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m2s[0m 401ms/step - accuracy: 0.4227 - loss: 4.2467[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 402ms/step - accuracy: 0.4248 - loss: 4.2080[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m1s[0m 402ms/step - accuracy: 0.4268 - loss: 4.1677[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 402ms/step - accuracy: 0.4275 - loss: 4.1335[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 402ms/step - accuracy: 0.4283 - loss: 4.1043[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 385ms/step - accuracy: 0.4288 - loss: 4.0780
Epoch 1: val_loss improved from inf to 3.49334, saving model to Models/name/Prueba_VGG16_block4/Prueba_VGG16_block4_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m9s[0m 482ms/step - accuracy: 0.4292 - loss: 4.0544 - val_accuracy: 0.3846 - val_loss: 3.4933
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 425ms/step - accuracy: 0.3333 - loss: 3.3471[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m6s[0m 425ms/step - accuracy: 0.4167 - loss: 2.7906[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m6s[0m 422ms/step - accuracy: 0.4259 - loss: 2.6925[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m5s[0m 421ms/step - accuracy: 0.4236 - loss: 2.6216[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m5s[0m 421ms/step - accuracy: 0.4389 - loss: 2.5040[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m5s[0m 421ms/step - accuracy: 0.4398 - loss: 2.4757[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m4s[0m 421ms/step - accuracy: 0.4348 - loss: 2.4761[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m4s[0m 422ms/step - accuracy: 0.4351 - loss: 2.4569[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m3s[0m 422ms/step - accuracy: 0.4341 - loss: 2.4354[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m3s[0m 422ms/step - accuracy: 0.4340 - loss: 2.4137[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m2s[0m 422ms/step - accuracy: 0.4345 - loss: 2.3904[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m2s[0m 421ms/step - accuracy: 0.4354 - loss: 2.3648[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m2s[0m 421ms/step - accuracy: 0.4364 - loss: 2.3391[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 421ms/step - accuracy: 0.4358 - loss: 2.3191[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m1s[0m 421ms/step - accuracy: 0.4349 - loss: 2.3009[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 421ms/step - accuracy: 0.4344 - loss: 2.2819[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 421ms/step - accuracy: 0.4354 - loss: 2.2608[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 403ms/step - accuracy: 0.4366 - loss: 2.2411
Epoch 2: val_loss improved from 3.49334 to 2.14990, saving model to Models/name/Prueba_VGG16_block4/Prueba_VGG16_block4_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m10s[0m 557ms/step - accuracy: 0.4376 - loss: 2.2235 - val_accuracy: 0.3846 - val_loss: 2.1499
Models/name/Prueba_VGG16_block4/Prueba_VGG16_block4_model.keras
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_2      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 40,870,856 (155.91 MB)
 Trainable params: 13,045,122 (49.76 MB)
 Non-trainable params: 1,735,488 (6.62 MB)
 Optimizer params: 26,090,246 (99.53 MB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.5312 - loss: 1.2459[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5234 - loss: 1.2694[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5156 - loss: 1.2680[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 987ms/step - accuracy: 0.5105 - loss: 1.2702[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 987ms/step - accuracy: 0.5074 - loss: 1.2714
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.3846 - loss: 2.1499[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.3846 - loss: 2.1499
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/gita24/anaconda3/envs/deep/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.3846    1.0000    0.5556        10
          PD     0.0000    0.0000    0.0000        16

    accuracy                         0.3846        26
   macro avg     0.1923    0.5000    0.2778        26
weighted avg     0.1479    0.3846    0.2137        26

0 0 0.40980392156862744
0 1 0.9882352941176471
1 0 0.40980392156862744
1 1 0.9882352941176471
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_3 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 False
block2_conv2 False
block2_pool False
block3_conv1 True
block3_conv2 True
block3_conv3 True
block3_pool True
block4_conv1 True
block4_conv2 True
block4_conv3 True
block4_pool True
block5_conv1 True
block5_conv2 True
block5_conv3 True
block5_pool True
global_average_pooling2d_3 True
dense True
prediction True
0 input_layer_3
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_3
20 dense
21 prediction
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_3      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 14,520,450 (55.39 MB)
 Non-trainable params: 260,160 (1016.25 KB)
Model Training:  Prueba_VGG16_block3 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m26s[0m 2s/step - accuracy: 0.3333 - loss: 2.8985[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 655ms/step - accuracy: 0.2917 - loss: 3.1162[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m9s[0m 660ms/step - accuracy: 0.2500 - loss: 3.1589 [1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m9s[0m 660ms/step - accuracy: 0.2396 - loss: 3.2067[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m8s[0m 659ms/step - accuracy: 0.2517 - loss: 3.1783[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m7s[0m 660ms/step - accuracy: 0.2653 - loss: 3.1099[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m7s[0m 660ms/step - accuracy: 0.2784 - loss: 3.0379[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m6s[0m 660ms/step - accuracy: 0.2879 - loss: 2.9729[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m5s[0m 660ms/step - accuracy: 0.2970 - loss: 2.9053[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m5s[0m 660ms/step - accuracy: 0.3040 - loss: 2.8366[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m4s[0m 661ms/step - accuracy: 0.3122 - loss: 2.7813[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m3s[0m 661ms/step - accuracy: 0.3220 - loss: 2.7248[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m3s[0m 661ms/step - accuracy: 0.3288 - loss: 2.6776[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m2s[0m 661ms/step - accuracy: 0.3343 - loss: 2.6344[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m1s[0m 661ms/step - accuracy: 0.3386 - loss: 2.5925[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 661ms/step - accuracy: 0.3442 - loss: 2.5493[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 661ms/step - accuracy: 0.3487 - loss: 2.5085[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 631ms/step - accuracy: 0.3525 - loss: 2.4726
Epoch 1: val_loss improved from inf to 0.88928, saving model to Models/name/Prueba_VGG16_block3/Prueba_VGG16_block3_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m14s[0m 737ms/step - accuracy: 0.3560 - loss: 2.4404 - val_accuracy: 0.6154 - val_loss: 0.8893
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 665ms/step - accuracy: 0.5000 - loss: 1.5138[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 662ms/step - accuracy: 0.4583 - loss: 1.5513[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m9s[0m 660ms/step - accuracy: 0.4537 - loss: 1.5800 [1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m9s[0m 669ms/step - accuracy: 0.4444 - loss: 1.5974[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m8s[0m 665ms/step - accuracy: 0.4489 - loss: 1.5654[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m7s[0m 662ms/step - accuracy: 0.4481 - loss: 1.5302[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m7s[0m 662ms/step - accuracy: 0.4522 - loss: 1.4941[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m6s[0m 661ms/step - accuracy: 0.4581 - loss: 1.4558[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m5s[0m 660ms/step - accuracy: 0.4628 - loss: 1.4251[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m5s[0m 660ms/step - accuracy: 0.4682 - loss: 1.3961[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m4s[0m 660ms/step - accuracy: 0.4711 - loss: 1.3728[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m3s[0m 660ms/step - accuracy: 0.4746 - loss: 1.3495[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m3s[0m 659ms/step - accuracy: 0.4795 - loss: 1.3256[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m2s[0m 659ms/step - accuracy: 0.4836 - loss: 1.3034[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m1s[0m 660ms/step - accuracy: 0.4861 - loss: 1.2845[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 660ms/step - accuracy: 0.4870 - loss: 1.2688[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 659ms/step - accuracy: 0.4878 - loss: 1.2568[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 630ms/step - accuracy: 0.4887 - loss: 1.2456
Epoch 2: val_loss improved from 0.88928 to 0.83448, saving model to Models/name/Prueba_VGG16_block3/Prueba_VGG16_block3_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m14s[0m 789ms/step - accuracy: 0.4896 - loss: 1.2355 - val_accuracy: 0.6923 - val_loss: 0.8345
Models/name/Prueba_VGG16_block3/Prueba_VGG16_block3_model.keras
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_3      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,821,512 (167.17 MB)
 Trainable params: 14,520,450 (55.39 MB)
 Non-trainable params: 260,160 (1016.25 KB)
 Optimizer params: 29,040,902 (110.78 MB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m3s[0m 1s/step - accuracy: 0.5000 - loss: 1.0307[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5000 - loss: 1.0149[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5069 - loss: 0.9824[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5161 - loss: 0.9634[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1s/step - accuracy: 0.5216 - loss: 0.9520
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.6923 - loss: 0.8345[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.6923 - loss: 0.8345
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.6667    0.4000    0.5000        10
          PD     0.7000    0.8750    0.7778        16

    accuracy                         0.6923        26
   macro avg     0.6833    0.6375    0.6389        26
weighted avg     0.6872    0.6923    0.6709        26

0 0 0.8058823529411764
0 1 0.6686274509803922
1 0 0.9400115340253749
1 1 0.4879892349096502
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_4 False
block1_conv1 False
block1_conv2 False
block1_pool False
block2_conv1 True
block2_conv2 True
block2_pool True
block3_conv1 True
block3_conv2 True
block3_conv3 True
block3_pool True
block4_conv1 True
block4_conv2 True
block4_conv3 True
block4_pool True
block5_conv1 True
block5_conv2 True
block5_conv3 True
block5_pool True
global_average_pooling2d_4 True
dense True
prediction True
0 input_layer_4
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_4
20 dense
21 prediction
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_4      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 14,741,890 (56.24 MB)
 Non-trainable params: 38,720 (151.25 KB)
Model Training:  Prueba_VGG16_block2 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m32s[0m 2s/step - accuracy: 0.3333 - loss: 1.9303[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m12s[0m 778ms/step - accuracy: 0.3750 - loss: 1.9034[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m11s[0m 790ms/step - accuracy: 0.3981 - loss: 1.8031[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m11s[0m 787ms/step - accuracy: 0.4236 - loss: 1.7131[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m10s[0m 785ms/step - accuracy: 0.4322 - loss: 1.6745[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m9s[0m 786ms/step - accuracy: 0.4389 - loss: 1.6314 [1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m8s[0m 788ms/step - accuracy: 0.4442 - loss: 1.5962[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m7s[0m 788ms/step - accuracy: 0.4512 - loss: 1.5624[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m7s[0m 788ms/step - accuracy: 0.4587 - loss: 1.5285[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m6s[0m 787ms/step - accuracy: 0.4678 - loss: 1.4949[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m5s[0m 787ms/step - accuracy: 0.4749 - loss: 1.4724[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m4s[0m 787ms/step - accuracy: 0.4816 - loss: 1.4503[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m3s[0m 787ms/step - accuracy: 0.4869 - loss: 1.4299[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m3s[0m 786ms/step - accuracy: 0.4921 - loss: 1.4105[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m2s[0m 786ms/step - accuracy: 0.4956 - loss: 1.3927[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 786ms/step - accuracy: 0.4985 - loss: 1.3766[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 786ms/step - accuracy: 0.5015 - loss: 1.3623[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 751ms/step - accuracy: 0.5044 - loss: 1.3490
Epoch 1: val_loss improved from inf to 1.14191, saving model to Models/name/Prueba_VGG16_block2/Prueba_VGG16_block2_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m16s[0m 857ms/step - accuracy: 0.5069 - loss: 1.3370 - val_accuracy: 0.4231 - val_loss: 1.1419
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m13s[0m 778ms/step - accuracy: 0.6667 - loss: 0.4054[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m12s[0m 798ms/step - accuracy: 0.6250 - loss: 0.5025[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m11s[0m 789ms/step - accuracy: 0.6574 - loss: 0.4832[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m11s[0m 787ms/step - accuracy: 0.6389 - loss: 0.5390[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m10s[0m 786ms/step - accuracy: 0.6244 - loss: 0.5886[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m9s[0m 785ms/step - accuracy: 0.6269 - loss: 0.6076 [1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m8s[0m 784ms/step - accuracy: 0.6359 - loss: 0.6106[1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m7s[0m 784ms/step - accuracy: 0.6372 - loss: 0.6317[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m7s[0m 784ms/step - accuracy: 0.6384 - loss: 0.6513[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m6s[0m 784ms/step - accuracy: 0.6346 - loss: 0.6686[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m5s[0m 783ms/step - accuracy: 0.6306 - loss: 0.6876[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m4s[0m 783ms/step - accuracy: 0.6255 - loss: 0.7032[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m3s[0m 783ms/step - accuracy: 0.6208 - loss: 0.7167[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m3s[0m 783ms/step - accuracy: 0.6164 - loss: 0.7280[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m2s[0m 783ms/step - accuracy: 0.6138 - loss: 0.7346[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 783ms/step - accuracy: 0.6113 - loss: 0.7424[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 783ms/step - accuracy: 0.6099 - loss: 0.7485[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 748ms/step - accuracy: 0.6084 - loss: 0.7541
Epoch 2: val_loss improved from 1.14191 to 1.03489, saving model to Models/name/Prueba_VGG16_block2/Prueba_VGG16_block2_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m16s[0m 889ms/step - accuracy: 0.6070 - loss: 0.7590 - val_accuracy: 0.3846 - val_loss: 1.0349
Models/name/Prueba_VGG16_block2/Prueba_VGG16_block2_model.keras
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_4      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 44,264,392 (168.86 MB)
 Trainable params: 14,741,890 (56.24 MB)
 Non-trainable params: 38,720 (151.25 KB)
 Optimizer params: 29,483,782 (112.47 MB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.5312 - loss: 0.8165[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5547 - loss: 0.7762[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.5816 - loss: 0.7394[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5940 - loss: 0.7203[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1s/step - accuracy: 0.6014 - loss: 0.7088
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.3846 - loss: 1.0349[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.3846 - loss: 1.0349
WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796f70803af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..151.061].
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.3125    0.5000    0.3846        10
          PD     0.5000    0.3125    0.3846        16

    accuracy                         0.3846        26
   macro avg     0.4062    0.4062    0.3846        26
weighted avg     0.4279    0.3846    0.3846        26

0 0 0.7339869281045752
0 1 0.7339869281045752
1 0 0.609519415609381
1 1 0.8576509034986544
(129, 256, 256, 3) <class 'numpy.ndarray'>
(129,) <class 'numpy.ndarray'>
Train data (103, 256, 256, 3), (103, 2), [45 58]
Test data (26, 256, 256, 3), (26, 2), [10 16]
input_layer_5 False
block1_conv1 True
block1_conv2 True
block1_pool True
block2_conv1 True
block2_conv2 True
block2_pool True
block3_conv1 True
block3_conv2 True
block3_conv3 True
block3_pool True
block4_conv1 True
block4_conv2 True
block4_conv3 True
block4_pool True
block5_conv1 True
block5_conv2 True
block5_conv3 True
block5_pool True
global_average_pooling2d_5 True
dense True
prediction True
0 input_layer_5
1 block1_conv1
2 block1_conv2
3 block1_pool
4 block2_conv1
5 block2_conv2
6 block2_pool
7 block3_conv1
8 block3_conv2
9 block3_conv3
10 block3_pool
11 block4_conv1
12 block4_conv2
13 block4_conv3
14 block4_pool
15 block5_conv1
16 block5_conv2
17 block5_conv3
18 block5_pool
19 global_average_pooling2d_5
20 dense
21 prediction
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_5      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 14,780,610 (56.38 MB)
 Trainable params: 14,780,610 (56.38 MB)
 Non-trainable params: 0 (0.00 B)
Model Training:  Prueba_VGG16_block1 


Epoch 1/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m34s[0m 2s/step - accuracy: 0.6667 - loss: 1.7611[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m14s[0m 892ms/step - accuracy: 0.6250 - loss: 1.7170[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m13s[0m 898ms/step - accuracy: 0.6204 - loss: 1.6038[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m12s[0m 901ms/step - accuracy: 0.6007 - loss: 1.5616[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m11s[0m 902ms/step - accuracy: 0.5939 - loss: 1.5380[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m10s[0m 905ms/step - accuracy: 0.5968 - loss: 1.4933[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m9s[0m 906ms/step - accuracy: 0.5999 - loss: 1.4512 [1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m9s[0m 906ms/step - accuracy: 0.5979 - loss: 1.4216[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m8s[0m 905ms/step - accuracy: 0.5911 - loss: 1.4042[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m7s[0m 905ms/step - accuracy: 0.5870 - loss: 1.3862[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m6s[0m 904ms/step - accuracy: 0.5832 - loss: 1.3686[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m5s[0m 904ms/step - accuracy: 0.5786 - loss: 1.3592[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m4s[0m 903ms/step - accuracy: 0.5735 - loss: 1.3551[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m3s[0m 902ms/step - accuracy: 0.5683 - loss: 1.3519[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m2s[0m 902ms/step - accuracy: 0.5645 - loss: 1.3467[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 902ms/step - accuracy: 0.5617 - loss: 1.3408[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 901ms/step - accuracy: 0.5598 - loss: 1.3336[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 860ms/step - accuracy: 0.5584 - loss: 1.3267
Epoch 1: val_loss improved from inf to 1.18032, saving model to Models/name/Prueba_VGG16_block1/Prueba_VGG16_block1_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m18s[0m 965ms/step - accuracy: 0.5571 - loss: 1.3206 - val_accuracy: 0.5769 - val_loss: 1.1803
Epoch 2/2
[1m 1/18[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m15s[0m 900ms/step - accuracy: 0.3333 - loss: 1.7488[1m 2/18[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m14s[0m 901ms/step - accuracy: 0.4583 - loss: 1.4558[1m 3/18[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m13s[0m 896ms/step - accuracy: 0.4907 - loss: 1.3353[1m 4/18[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m12s[0m 900ms/step - accuracy: 0.5035 - loss: 1.2498[1m 5/18[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m11s[0m 903ms/step - accuracy: 0.5094 - loss: 1.2204[1m 6/18[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m10s[0m 904ms/step - accuracy: 0.5171 - loss: 1.1814[1m 7/18[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m9s[0m 906ms/step - accuracy: 0.5283 - loss: 1.1430 [1m 8/18[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m9s[0m 903ms/step - accuracy: 0.5378 - loss: 1.1105[1m 9/18[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m8s[0m 902ms/step - accuracy: 0.5418 - loss: 1.0844[1m10/18[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m7s[0m 904ms/step - accuracy: 0.5443 - loss: 1.0609[1m11/18[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m6s[0m 903ms/step - accuracy: 0.5472 - loss: 1.0407[1m12/18[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m5s[0m 902ms/step - accuracy: 0.5513 - loss: 1.0235[1m13/18[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m4s[0m 902ms/step - accuracy: 0.5533 - loss: 1.0137[1m14/18[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m3s[0m 902ms/step - accuracy: 0.5546 - loss: 1.0064[1m15/18[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m2s[0m 902ms/step - accuracy: 0.5561 - loss: 0.9988[1m16/18[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m1s[0m 902ms/step - accuracy: 0.5578 - loss: 0.9913[1m17/18[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 902ms/step - accuracy: 0.5596 - loss: 0.9836[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 861ms/step - accuracy: 0.5614 - loss: 0.9767
Epoch 2: val_loss improved from 1.18032 to 1.12874, saving model to Models/name/Prueba_VGG16_block1/Prueba_VGG16_block1_model.keras
[1m18/18[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m18s[0m 1s/step - accuracy: 0.5631 - loss: 0.9705 - val_accuracy: 0.5000 - val_loss: 1.1287
Models/name/Prueba_VGG16_block1/Prueba_VGG16_block1_model.keras
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 256, 256, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv1 (Conv2D)           │ (None, 256, 256, 64)   │         1,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_conv2 (Conv2D)           │ (None, 256, 256, 64)   │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1_pool (MaxPooling2D)      │ (None, 128, 128, 64)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv1 (Conv2D)           │ (None, 128, 128, 128)  │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_conv2 (Conv2D)           │ (None, 128, 128, 128)  │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2_pool (MaxPooling2D)      │ (None, 64, 64, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv1 (Conv2D)           │ (None, 64, 64, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv2 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_conv3 (Conv2D)           │ (None, 64, 64, 256)    │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3_pool (MaxPooling2D)      │ (None, 32, 32, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv1 (Conv2D)           │ (None, 32, 32, 512)    │     1,180,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv2 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_conv3 (Conv2D)           │ (None, 32, 32, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4_pool (MaxPooling2D)      │ (None, 16, 16, 512)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv1 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv2 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_conv3 (Conv2D)           │ (None, 16, 16, 512)    │     2,359,808 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5_pool (MaxPooling2D)      │ (None, 8, 8, 512)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_5      │ (None, 512)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 128)            │        65,664 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ prediction (Dense)              │ (None, 2)              │           258 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 44,341,832 (169.15 MB)
 Trainable params: 14,780,610 (56.38 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 29,561,222 (112.77 MB)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m4s[0m 1s/step - accuracy: 0.5625 - loss: 0.8886[1m2/4[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m2s[0m 1s/step - accuracy: 0.5938 - loss: 0.8088[1m3/4[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m1s[0m 1s/step - accuracy: 0.6146 - loss: 0.7790[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.6260 - loss: 0.7629[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1s/step - accuracy: 0.6328 - loss: 0.7532
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step - accuracy: 0.5000 - loss: 1.1287[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step - accuracy: 0.5000 - loss: 1.1287
WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796f715cf8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
(26,) (26,)
              precision    recall  f1-score   support

          HC     0.4118    0.7000    0.5185        10
          PD     0.6667    0.3750    0.4800        16

    accuracy                         0.5000        26
   macro avg     0.5392    0.5375    0.4993        26
weighted avg     0.5686    0.5000    0.4948        26

0 0 0.6018608227604767
0 1 0.8663860053825452
1 0 0.6503652441368705
1 1 0.8224913494809689
Results/name_fine_tunning.xlsx
